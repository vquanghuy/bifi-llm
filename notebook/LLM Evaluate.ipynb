{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a02a6af-6b3d-4480-8f22-4f203e0e89d2",
   "metadata": {},
   "source": [
    "# Evaluate GitHub Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16321896-dd05-48cf-995f-10b1a422a10f",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85944a5f-510a-4d95-8c14-4dc84d686b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_json_from_folder(folder_path):\n",
    "  \"\"\"\n",
    "  Loads all JSON files from a specified folder.\n",
    "\n",
    "  Args:\n",
    "    folder_path: The path to the folder containing the JSON files.\n",
    "\n",
    "  Returns:\n",
    "    A list containing all JSON objects from the files.\n",
    "  \"\"\"\n",
    "\n",
    "  data_packages = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "      filepath = os.path.join(folder_path, filename)\n",
    "      try:\n",
    "        with open(filepath, 'r') as f:\n",
    "          data = json.load(f)\n",
    "          data_packages.append(data)\n",
    "      except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON in file {filename}: {e}\")\n",
    "          \n",
    "  return data_packages\n",
    "\n",
    "def load_json_from_file(json_file):\n",
    "    try:\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON in file {json_file}: {e}\")  # Corrected line\n",
    "        return None\n",
    "\n",
    "    return data\n",
    "\n",
    "def write_json_to_file(json_data, filename, indent=4):\n",
    "  \"\"\"\n",
    "  Writes JSON data to a file.\n",
    "\n",
    "  Args:\n",
    "    json_data: The JSON data to write (can be a dictionary or a list).\n",
    "    filename: The name of the file to write to.\n",
    "    indent: (Optional) The number of spaces to use for indentation. \n",
    "            Defaults to 4 for better readability.\n",
    "  \"\"\"\n",
    "\n",
    "  with open(filename, 'w') as f:\n",
    "    json.dump(json_data, f, indent=indent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f71657c6-51e3-49d0-a246-9a2f7c5ac493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def validate_code(code_str):\n",
    "  \"\"\"\n",
    "  Validates Python code and returns error information if any.\n",
    "\n",
    "  Args:\n",
    "    code_str: The Python code as a string.\n",
    "\n",
    "  Returns:\n",
    "    None if the code is valid, otherwise a string describing the syntax error.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    ast.parse(code_str)\n",
    "    return None  # No error\n",
    "  except SyntaxError as e:\n",
    "    return str(e)  # Return the error message as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cff8a2ad-8a2e-4148-b42b-00fd2f8b9ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_key_in_json(json_obj, key_to_replace, new_value):\n",
    "  \"\"\"\n",
    "  Creates a new JSON object with a specific key replaced.\n",
    "\n",
    "  Args:\n",
    "    json_obj: The original JSON object.\n",
    "    key_to_replace: The key to be replaced.\n",
    "    new_value: The new value for the key.\n",
    "\n",
    "  Returns:\n",
    "    A new JSON object with the key replaced.\n",
    "  \"\"\"\n",
    "\n",
    "  new_json_obj = json.loads(json.dumps(json_obj))  # Create a deep copy\n",
    "  new_json_obj[key_to_replace] = new_value\n",
    "  return new_json_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f81b545-a086-4d14-9e7b-e98f1552fc3b",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b204ec-f193-42d5-bb74-78ad545e838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_python_dataset = \"../github-python-test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e4d5c9-d2c5-4159-9845-93b683faeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original paper use the 3 4 as hold-out test set\n",
    "test_dataset = [];\n",
    "test_dataset.append(load_json_from_file(os.path.join(github_python_dataset, 'model-fixer.pred.evaluated.3.json')))\n",
    "test_dataset.append(load_json_from_file(os.path.join(github_python_dataset, 'model-fixer.pred.evaluated.4.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60761007-dc6f-486e-8f38-f6683c88463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 15055\n",
      "First code:\n",
      " def test_pp_no_constraint ( self ) :\n",
      "    filenames = [ tests . get_data_path ( ( \"str\" , \"str\" , \"str\" ) ) ]\n",
      "    pp_constraints = pp . _convert_constraints ( None )\n",
      "    pp_loader = iris . fileformats . rules . Loader ( pp . load , { } ,\n",
      "        convert , pp . _load_rules )\n",
      "    cubes = list ( load_cubes ( filenames , None , pp_loader , pp_constraints )\n",
      "    self . assertEqual ( len ( cubes ) , 152 )\n",
      "\n",
      "Error (if any): '(' was never closed (<unknown>, line 6)\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(test_dataset[0]) + len(test_dataset[1])\n",
    "first_code = test_dataset[0][0]['src']['string_format']\n",
    "\n",
    "print(f\"Total number of samples: {total_samples}\")\n",
    "print(f\"First code:\\n {first_code}\")\n",
    "print(f\"Error (if any): {validate_code(first_code)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3706aab-3fd9-4c5b-832d-2e5b5bff6987",
   "metadata": {},
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "131e7764-fac2-4f45-a06b-17bc11b43be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a749d0b2-f689-4ad2-9cd3-5df08c198152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare token\n",
    "torch.cuda.empty_cache()\n",
    "hf_token = os.environ.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "568fa547-9692-4f03-a956-6787684c04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare instruction\n",
    "python_syntax_fixer_instruction = \"You are an expert Python code fixer. \\\n",
    "             You will receive input in the following format: \\n\\n \\\n",
    "             [Fix] | <error code>\\n \\\n",
    "             <python code snippet>\\n\\n \\\n",
    "             Your task is to ONLY provide the corrected Python code with NO explanations or additional text. \\n \\\n",
    "             Do not include the original error code in your response and do not format the code. \\\n",
    "             Treat the code snippet as regular text. Do NOT put any prefix, only plain text as code only.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6adc21a0-78b1-494c-b108-0af37cb0d9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a957be4c5d3a41a8843d27d4f36fddb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and instruction\n",
    "instruct_model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    token=hf_token,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d58c2-d3a6-465c-b6cc-40ee4b75362a",
   "metadata": {},
   "source": [
    "## Process fixing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6aedcc74-821c-4b64-bf09-5c02dc62d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_code(code_snippet):\n",
    "    code_error = validate_code(code_snippet)\n",
    "    messages = [\n",
    "        { \"role\": \"system\", \"content\": python_syntax_fixer_instruction }\n",
    "    ]\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"[Fix] | {code_error}\\n{code_snippet}\"})\n",
    "    \n",
    "    outputs = pipe(messages, max_new_tokens=512, pad_token_id=pipe.tokenizer.eos_token_id)\n",
    "    \n",
    "    return outputs[0][\"generated_text\"][-1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f249adb-e32e-466c-8d1f-4511e65b17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "FIXING_ATTEMP_COUNT = 10\n",
    "\n",
    "def perform_fixing_code(dataset):\n",
    "    results = []\n",
    "    for item in tqdm(dataset, desc=\"Fixing code\"):\n",
    "        code_snippet = item['src']['string_format']\n",
    "        \n",
    "        fixing_attempts = []\n",
    "        # Sub-progress bar for fixing attempts\n",
    "        with tqdm(total=FIXING_ATTEMP_COUNT, desc=\"Fixing attempts\", leave=False) as pbar:  \n",
    "            for _ in range(FIXING_ATTEMP_COUNT):\n",
    "                fixed_code = fix_code(code_snippet)\n",
    "                remain_error = validate_code(fixed_code)\n",
    "                fixing_attempts.append({\n",
    "                    \"string_format\": fixed_code,\n",
    "                    \"err_obj\": 0 if remain_error is None \\\n",
    "                                else { \"msg\": item[\"orig_err_obj\"][\"msg\"], \"msg_detailed\": remain_error }\n",
    "                })\n",
    "                pbar.update(1) # update progress bar\n",
    "\n",
    "                # If the code is already fixed, no need to retry\n",
    "                if remain_error is None:\n",
    "                    pbar.update(10)\n",
    "                    break\n",
    "            \n",
    "            pbar.close() # close the progress bar after the loop\n",
    "            # Update the return result\n",
    "            results.append(replace_key_in_json(item, \"pred\", fixing_attempts))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f95bd-abbb-48cf-a152-1fd85d838ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform fix on dataset\n",
    "fixed_set_1 = perform_fixing_code(test_dataset[0])\n",
    "\n",
    "# Write the result to files\n",
    "write_json_to_file(\n",
    "    fixed_set_1,\n",
    "    os.path.join(github_python_dataset, 'model-fixer.pred.evaluated-llm.3.json'),\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "da2c62dd-d355-4506-9b96-ef1c093f0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform fix on dataset\n",
    "fixed_set_2 = perform_fixing_code(test_dataset[1])\n",
    "\n",
    "# Write the result to files\n",
    "write_json_to_file(\n",
    "    fixed_set_2,\n",
    "    os.path.join(github_python_dataset, 'model-fixer.pred.evaluated-llm.4.json'),\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e83e7e7-55ed-48ba-b010-2430a6856eac",
   "metadata": {},
   "source": [
    "## Evaluate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0769589-5dc5-4a9c-ad43-718e97f03139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "def get_test_result(pred_dir, pred_fname, pred_set):\n",
    "    #\n",
    "    def collate_eval():\n",
    "      success  = []; denom = 0\n",
    "      success_by_group = defaultdict(list); denom_by_group = defaultdict(int)\n",
    "      agg_obj = {}\n",
    "      for split in {3,4}: #heldout test set\n",
    "        print ('split', split)\n",
    "        pred_dir_path   = Path(f'{pred_dir}')\n",
    "        pred_path  = pred_dir_path/pred_fname\n",
    "        pred_eval_path = f'{pred_path}.{pred_set}.{split}.json'\n",
    "        print(pred_eval_path)\n",
    "        eval_objs = json.load(open(pred_eval_path))\n",
    "        for eval_obj in eval_objs:\n",
    "          progid = eval_obj['progid']\n",
    "          orig_err_type = eval_obj['orig_err_obj']['msg']\n",
    "          if 'indent' in orig_err_type:\n",
    "              orig_err_type = 'indentation error'\n",
    "          denom += 1\n",
    "          denom_by_group[orig_err_type] += 1\n",
    "          for k, pred_obj in enumerate(eval_obj['pred']):\n",
    "            pred_err_obj = pred_obj['err_obj']\n",
    "            if (pred_err_obj == 0):\n",
    "              name = '{:02d}-{}-{:03d}'.format(split, progid, k)\n",
    "              success.append(name)\n",
    "              success_by_group[orig_err_type].append(name)\n",
    "      return success, denom, success_by_group, denom_by_group\n",
    "    #\n",
    "    def print_stats(name_list, _denom):\n",
    "      top1 = set()\n",
    "      for name in name_list:\n",
    "        split, progid, k = name.split('-')\n",
    "        if int(split) in {3,4}: #test set\n",
    "          if int(k)==0:\n",
    "            top1.add(f'{split}-{progid}')\n",
    "      acc = len(top1)/float(_denom)*100\n",
    "      print ('   acc: {} ({:.1f}%) | denom {}'.format(len(top1), acc, _denom))\n",
    "      return acc\n",
    "    #\n",
    "    success, denom, success_by_group, denom_by_group = collate_eval()\n",
    "    acc_dict = {}\n",
    "    print ('Total'); acc = print_stats(success, denom); acc_dict['total'] = acc\n",
    "    print ('-'*50)\n",
    "    for err_type in success_by_group:\n",
    "        print (f'{err_type.capitalize()}')\n",
    "        acc = print_stats(success_by_group[err_type], denom_by_group[err_type])\n",
    "        acc_dict[err_type] = acc\n",
    "        \n",
    "    json.dump(acc_dict, open(Path(pred_dir)/f'stats.{pred_set}.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41f8d731-2c9f-4861-b1f7-8cab4bf04ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 3\n",
      "../github-python-test/model-fixer.pred.evaluated-llm.3.json\n",
      "split 4\n",
      "../github-python-test/model-fixer.pred.evaluated-llm.4.json\n",
      "Total\n",
      "   acc: 12295 (81.7%) | denom 15055\n",
      "--------------------------------------------------\n",
      "Unbalanced (){}[]\n",
      "   acc: 3282 (82.1%) | denom 3999\n",
      "Invalid syntax\n",
      "   acc: 3986 (83.9%) | denom 4749\n",
      "Indentation error\n",
      "   acc: 5027 (79.7%) | denom 6307\n"
     ]
    }
   ],
   "source": [
    "# Show LLM test result\n",
    "get_test_result(github_python_dataset, 'model-fixer.pred', 'evaluated-llm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b3cf760-bab1-4126-941a-98399e5918dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 3\n",
      "../github-python-test/model-fixer.pred.evaluated.3.json\n",
      "split 4\n",
      "../github-python-test/model-fixer.pred.evaluated.4.json\n",
      "Total\n",
      "   acc: 13503 (89.7%) | denom 15055\n",
      "--------------------------------------------------\n",
      "Unbalanced (){}[]\n",
      "   acc: 3892 (97.3%) | denom 3999\n",
      "Invalid syntax\n",
      "   acc: 4287 (90.3%) | denom 4749\n",
      "Indentation error\n",
      "   acc: 5324 (84.4%) | denom 6307\n"
     ]
    }
   ],
   "source": [
    "# Show BIFI test result\n",
    "get_test_result(github_python_dataset, 'model-fixer.pred', 'evaluated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7581e10c-6877-408e-8abe-672a42453e70",
   "metadata": {},
   "source": [
    "# Evaluate Pruto-DeepFix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e5475e-d028-46af-81a6-065802a12cf4",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d35cad9-681b-43db-8ccb-1148b4a0d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def get_error_code_snippets_from_db(db_path):\n",
    "    \"\"\"\n",
    "    Retrieves all code that contains error in the SQLite database.\n",
    "    \n",
    "    Args:\n",
    "    db_path: Path to the SQLite database file.\n",
    "    \n",
    "    Returns:\n",
    "    A list of all code contains error.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(\"SELECT * FROM Code WHERE errorcount != 0\")\n",
    "        data = [row for row in cursor.fetchall()]\n",
    "        return data\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "308813e6-c820-4789-b522-18255573cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def compile_code(code):\n",
    "  \"\"\"\n",
    "  Compiles the given C code using gcc and returns the error message \n",
    "  if compilation fails.\n",
    "\n",
    "  Args:\n",
    "    code: The C code as a string.\n",
    "\n",
    "  Returns:\n",
    "    An empty string if compilation is successful, \n",
    "    the error message otherwise.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    with open('temp.c', 'w') as f:\n",
    "      f.write(code)\n",
    "\n",
    "    result = subprocess.run(['gcc', 'temp.c', '-o', 'temp'], \n",
    "                             capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode == 0:\n",
    "      return \"\"  # No error message\n",
    "    else:\n",
    "      return result.stderr  # Return the error message\n",
    "\n",
    "  finally:\n",
    "    import os\n",
    "    try:\n",
    "      os.remove('temp.c')\n",
    "      os.remove('temp')\n",
    "    except OSError:\n",
    "      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a52747d3-6b43-45bd-873c-d69693ca4ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_backticks(text):\n",
    "  \"\"\"\n",
    "  Removes backtick code formatting from a string.\n",
    "\n",
    "  Args:\n",
    "    text: The string containing code blocks enclosed in backticks.\n",
    "\n",
    "  Returns:\n",
    "    The string with backtick code formatting removed.\n",
    "  \"\"\"\n",
    "  pattern = r'```(?:[a-z]+)?\\n(.*?)```'  # Matches code blocks with optional language\n",
    "  return re.sub(pattern, r'\\1', text, flags=re.DOTALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f1e25c-8866-4031-ae89-8a0e78d1d8c7",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f63208-2f6c-42f4-b013-5f7990cd7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "prutor_deepfix_dataset_db = '../prutor-deepfix-09-12-2017/prutor-deepfix-09-12-2017.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bf91a89-6bcb-4c94-8131-e722e887bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = get_error_code_snippets_from_db(prutor_deepfix_dataset_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "965f28ed-8b1a-4a98-84e4-b33da841674e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('prog19941',\n",
       " 'user801',\n",
       " 'prob90',\n",
       " '#include <stdio.h>\\nint main(){\\n    int k,n;\\n    scanf(\"%d%d\",&k,&n);\\n    int a[n];\\n    int i=0;\\n    for(i=0;i<n;i++)\\n    scanf(\"%d\",&a[i]);\\n    int flag=0;\\n    int m=0;\\n    while(m<n)\\n    {\\n        int j=0;\\n        while(j<n)\\n        {\\n            //if(m!=j)\\n            {\\n                if (a[j]==(k-[ai]))\\n                //if ((a[m]+a[j])==k)\\n                flag=1;\\n               \\n            }  \\n            j++;    \\n        }\\n        m++;\\n    }\\n    if (flag==1)\\n    printf(\"lucky\");\\n    else \\n    printf(\"unlucky\");\\n    return 0;\\n}',\n",
       " 'In function ‘main’:\\n18:30: error: expected expression before ‘[’ token\\n                 if (a[j]==(k-[ai]))\\n                              ^\\n18:31: error: ‘ai’ undeclared (first use in this function)\\n                 if (a[j]==(k-[ai]))\\n                               ^\\n18:31: note: each undeclared identifier is reported only once for each function it appears in',\n",
       " 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the structure of 1st record\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16e7c8b5-be06-4c7d-b2ae-680fbad1009e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp.c: In function ‘main’:\\ntemp.c:18:30: error: expected expression before ‘[’ token\\n   18 |                 if (a[j]==(k-[ai]))\\n      |                              ^\\ntemp.c:18:31: error: ‘ai’ undeclared (first use in this function); did you mean ‘i’?\\n   18 |                 if (a[j]==(k-[ai]))\\n      |                               ^~\\n      |                               i\\ntemp.c:18:31: note: each undeclared identifier is reported only once for each function it appears in\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check compliation - should CONTAIN error\n",
    "compile_code(data[0][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777090e6-0953-4565-b98a-1589563834ec",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5627936d-8bdc-492d-b558-c726e2671fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26bb7c88-1b94-49cc-9fab-b28d7919977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare token\n",
    "torch.cuda.empty_cache()\n",
    "hf_token = os.environ.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b1504b8-e1b5-44f8-8ca1-ccc2193df9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare instruction\n",
    "cpp_syntax_fixer_instruction = \"You are an expert C/C++ code fixer. \\\n",
    "             You will receive input in the following format: \\n\\n \\\n",
    "             [Fix] | <error code>\\n \\\n",
    "             <code snippet>\\n\\n \\\n",
    "             Your task is to ONLY provide the corrected C/C++ code with NO explanations or additional text. \\n \\\n",
    "             Do not include the original error code in your response and do not format the code. \\\n",
    "             Treat the code snippet as regular text. Do NOT put any prefix, only plain text as code only.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6af5323-52fb-42d5-9d3a-ddef973ba40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c2a5da69e44fcf886d548c32b4be76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and instruction\n",
    "instruct_model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    token=hf_token,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558cc713-1330-40da-93df-0f60b9316716",
   "metadata": {},
   "source": [
    "## Process fixing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce8c2111-32fc-431d-8759-e67d4c24b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_code(code_snippet):\n",
    "    code_error = compile_code(code_snippet)\n",
    "    messages = [\n",
    "        { \"role\": \"system\", \"content\": cpp_syntax_fixer_instruction }\n",
    "    ]\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"[Fix] | {code_error}\\n{code_snippet}\"})\n",
    "    \n",
    "    outputs = pipe(messages, max_new_tokens=512, pad_token_id=pipe.tokenizer.eos_token_id)\n",
    "    \n",
    "    return outputs[0][\"generated_text\"][-1][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119de68-7efa-408f-852b-bb80e2b3240c",
   "metadata": {},
   "source": [
    "### Fix 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46f7f3a7-312e-46a9-b662-56863dd3e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix 1 record\n",
    "input_code = data[0][3]\n",
    "output_code = fix_code(input_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8822a462-55b6-48c9-9d62-0cd864a61b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <stdio.h>\n",
      "int main(){\n",
      "    int k,n;\n",
      "    scanf(\"%d%d\",&k,&n);\n",
      "    int a[n];\n",
      "    int i=0;\n",
      "    for(i=0;i<n;i++)\n",
      "    scanf(\"%d\",&a[i]);\n",
      "    int flag=0;\n",
      "    int m=0;\n",
      "    while(m<n)\n",
      "    {\n",
      "        int j=0;\n",
      "        while(j<n)\n",
      "        {\n",
      "            //if(m!=j)\n",
      "            {\n",
      "                if (a[j]==(k-[ai]))\n",
      "                //if ((a[m]+a[j])==k)\n",
      "                flag=1;\n",
      "               \n",
      "            }  \n",
      "            j++;    \n",
      "        }\n",
      "        m++;\n",
      "    }\n",
      "    if (flag==1)\n",
      "    printf(\"lucky\");\n",
      "    else \n",
      "    printf(\"unlucky\");\n",
      "    return 0;\n",
      "}\n",
      "--- ERROR ---\n",
      "temp.c: In function ‘main’:\n",
      "temp.c:18:30: error: expected expression before ‘[’ token\n",
      "   18 |                 if (a[j]==(k-[ai]))\n",
      "      |                              ^\n",
      "temp.c:18:31: error: ‘ai’ undeclared (first use in this function); did you mean ‘i’?\n",
      "   18 |                 if (a[j]==(k-[ai]))\n",
      "      |                               ^~\n",
      "      |                               i\n",
      "temp.c:18:31: note: each undeclared identifier is reported only once for each function it appears in\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show input code and check compilation\n",
    "print(input_code)\n",
    "print('--- ERROR ---')\n",
    "print(compile_code(input_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "150e921c-1f6c-4fb3-8785-0c254bf664f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <stdio.h>\n",
      "\n",
      "int main(){\n",
      "    int k,n;\n",
      "    scanf(\"%d%d\",&k,&n);\n",
      "    int a[n];\n",
      "    int i=0;\n",
      "    for(i=0;i<n;i++)\n",
      "    scanf(\"%d\",&a[i]);\n",
      "    int flag=0;\n",
      "    int m=0;\n",
      "    while(m<n)\n",
      "    {\n",
      "        int j=0;\n",
      "        while(j<n)\n",
      "        {\n",
      "            if (a[j]==(k-(a[i])))\n",
      "            flag=1;\n",
      "            j++;    \n",
      "        }\n",
      "        m++;\n",
      "        i++; // Increment i to avoid infinite loop\n",
      "    }\n",
      "    if (flag==1)\n",
      "    printf(\"lucky\");\n",
      "    else \n",
      "    printf(\"unlucky\");\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "--- ERROR ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show input code and check compilation\n",
    "output_code = remove_backticks(output_code)\n",
    "\n",
    "print(output_code)\n",
    "print('--- ERROR ---')\n",
    "print(compile_code(output_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab7b95-369e-4e92-89c5-565b9173d4f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e41cb4-95a3-4804-b0cd-b5f12a5ed56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cbf41-48f0-43f2-b573-ba4ff6fbe963",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a Python syntax error correction expert. You will receive code snippets with syntax errors, prefixed with [Fix]. Each input will have two parts separated by a vertical bar (|). You will only fix the provided code, without any additional explanation.\"},\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=128,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e39ccc-b21c-4226-ad33-59486c58504a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6defeb76a36f460b91cb495f58722cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'def greet(name):\\n  print(\"Hello, \" + name)'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "error_code = \"SyntaxError: invalid syntax\"\n",
    "code_snippet = \"\"\"\n",
    "def greet(name):\n",
    "  print(\"Hello, \" + name \n",
    "\n",
    "greet(\"Alice\")\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    { \n",
    "        \"role\": \"system\", \n",
    "        \"content\": \\\n",
    "            \"You are an expert Python code fixer. \\\n",
    "             You will receive input in the following format: \\n\\n \\\n",
    "             [Fix] | <error code>\\n \\\n",
    "             <python code snippet>\\n\\n \\\n",
    "             Your task is to ONLY provide the corrected Python code with NO explanations or additional text. \\n \\\n",
    "             Do not include the original error code in your response and do not format the code. \\\n",
    "             Treat the code snippet as regular text.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": f\"\"\"\n",
    "[Fix] | {error_code}\n",
    "{code_snippet}\n",
    "\"\"\"})\n",
    "\n",
    "outputs = pipe(messages, max_new_tokens=256)\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e59877aa-a023-439f-9b54-22c1d0ba5137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def greet(name):\\n  print(\"Hello, \" + name)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_code = outputs[0][\"generated_text\"][-1]['content']\n",
    "fixed_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed0263b8-c4df-48d5-820f-c1740a9e1133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'(' was never closed (<unknown>, line 3)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_code(code_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e3e0e23-20e7-4b6a-8dca-2cddca62e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_code(fixed_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e09ea6-79ce-472e-899f-c716c030db50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
