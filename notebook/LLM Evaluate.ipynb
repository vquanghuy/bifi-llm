{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969bcfd6-7ec0-4779-86bd-6e047d6ff1ab",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85944a5f-510a-4d95-8c14-4dc84d686b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_json_from_folder(folder_path):\n",
    "  \"\"\"\n",
    "  Loads all JSON files from a specified folder.\n",
    "\n",
    "  Args:\n",
    "    folder_path: The path to the folder containing the JSON files.\n",
    "\n",
    "  Returns:\n",
    "    A list containing all JSON objects from the files.\n",
    "  \"\"\"\n",
    "\n",
    "  all_data = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "      filepath = os.path.join(folder_path, filename)\n",
    "      try:\n",
    "        with open(filepath, 'r') as f:\n",
    "          data = json.load(f)\n",
    "          all_data.extend(data)\n",
    "      except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON in file {filename}: {e}\")\n",
    "  return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f71657c6-51e3-49d0-a246-9a2f7c5ac493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def validate_code(code_str):\n",
    "  \"\"\"\n",
    "  Validates Python code and returns error information if any.\n",
    "\n",
    "  Args:\n",
    "    code_str: The Python code as a string.\n",
    "\n",
    "  Returns:\n",
    "    None if the code is valid, otherwise a string describing the syntax error.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    ast.parse(code_str)\n",
    "    return None  # No error\n",
    "  except SyntaxError as e:\n",
    "    return str(e)  # Return the error message as a string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a02a6af-6b3d-4480-8f22-4f203e0e89d2",
   "metadata": {},
   "source": [
    "# Evaluate GitHub Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f81b545-a086-4d14-9e7b-e98f1552fc3b",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2e4d5c9-d2c5-4159-9845-93b683faeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_python_dataset = \"../github-python-test\"\n",
    "all_data = load_json_from_folder(github_python_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60761007-dc6f-486e-8f38-f6683c88463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of objects: 37639\n",
      "First code:\n",
      " def test_delitem_keyerror ( self ) :\n",
      "    e = EntryBase ( req_ ( )\n",
      "    del e [ \"str\" ]\n",
      "\n",
      "Error (if any): '(' was never closed (<unknown>, line 2)\n"
     ]
    }
   ],
   "source": [
    "total_records = len(all_data)\n",
    "first_code = all_data[0]['src']['string_format']\n",
    "\n",
    "print(f\"Total number of objects: {total_records}\")\n",
    "print(f\"First code:\\n {first_code}\")\n",
    "print(f\"Error (if any): {validate_code(first_code)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3706aab-3fd9-4c5b-832d-2e5b5bff6987",
   "metadata": {},
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "131e7764-fac2-4f45-a06b-17bc11b43be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, PeftModel, get_peft_model\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8bffb0f-d0e4-4962-9b11-81f2d440527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set HF token as env variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a749d0b2-f689-4ad2-9cd3-5df08c198152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare token\n",
    "torch.cuda.empty_cache()\n",
    "hf_token = os.environ.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "568fa547-9692-4f03-a956-6787684c04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare instruction\n",
    "python_syntax_fixer_instruction = \"You are an expert Python code fixer. \\\n",
    "             You will receive input in the following format: \\n\\n \\\n",
    "             [Fix] | <error code>\\n \\\n",
    "             <python code snippet>\\n\\n \\\n",
    "             Your task is to ONLY provide the corrected Python code with NO explanations or additional text. \\n \\\n",
    "             Do not include the original error code in your response and do not format the code. \\\n",
    "             Treat the code snippet as regular text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6aedcc74-821c-4b64-bf09-5c02dc62d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for fixing code\n",
    "def fix_code(code_snippet, error_code):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": python_syntax_fixer_instruction}\n",
    "    ]\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"[Fix] | {error_code}\\n{code_snippet}\"})\n",
    "    outputs = pipe(messages, max_new_tokens=256)\n",
    "    return outputs[0][\"generated_text\"][-1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6adc21a0-78b1-494c-b108-0af37cb0d9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41101d2813e46e6b9d773b368d4fe8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model and instruction\n",
    "instruct_model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    token=hf_token,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6398b71b-be79-4ab4-8a69-e6959973a22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'def test_delitem_keyerror ( self ) :\\n    e = EntryBase ( req_ () )\\n    del e[ \"str\" ]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_code = fix_code(first_code, validate_code(first_code))\n",
    "fixed_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb88badd-7a91-48d1-8f5d-455696b2b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_code(fixed_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0063a50b-da24-45c1-a518-0978e6a685c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def test_delitem_keyerror ( self ) :\\n    e = EntryBase ( req_ ( )\\n    del e [ \"str\" ]\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab7b95-369e-4e92-89c5-565b9173d4f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e41cb4-95a3-4804-b0cd-b5f12a5ed56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cbf41-48f0-43f2-b573-ba4ff6fbe963",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a Python syntax error correction expert. You will receive code snippets with syntax errors, prefixed with [Fix]. Each input will have two parts separated by a vertical bar (|). You will only fix the provided code, without any additional explanation.\"},\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=128,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e39ccc-b21c-4226-ad33-59486c58504a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6defeb76a36f460b91cb495f58722cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'def greet(name):\\n  print(\"Hello, \" + name)'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "error_code = \"SyntaxError: invalid syntax\"\n",
    "code_snippet = \"\"\"\n",
    "def greet(name):\n",
    "  print(\"Hello, \" + name \n",
    "\n",
    "greet(\"Alice\")\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    { \n",
    "        \"role\": \"system\", \n",
    "        \"content\": \\\n",
    "            \"You are an expert Python code fixer. \\\n",
    "             You will receive input in the following format: \\n\\n \\\n",
    "             [Fix] | <error code>\\n \\\n",
    "             <python code snippet>\\n\\n \\\n",
    "             Your task is to ONLY provide the corrected Python code with NO explanations or additional text. \\n \\\n",
    "             Do not include the original error code in your response and do not format the code. \\\n",
    "             Treat the code snippet as regular text.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": f\"\"\"\n",
    "[Fix] | {error_code}\n",
    "{code_snippet}\n",
    "\"\"\"})\n",
    "\n",
    "outputs = pipe(messages, max_new_tokens=256)\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e59877aa-a023-439f-9b54-22c1d0ba5137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def greet(name):\\n  print(\"Hello, \" + name)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_code = outputs[0][\"generated_text\"][-1]['content']\n",
    "fixed_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed0263b8-c4df-48d5-820f-c1740a9e1133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'(' was never closed (<unknown>, line 3)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_code(code_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e3e0e23-20e7-4b6a-8dca-2cddca62e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_code(fixed_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e09ea6-79ce-472e-899f-c716c030db50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
