{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "969bcfd6-7ec0-4779-86bd-6e047d6ff1ab",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a02a6af-6b3d-4480-8f22-4f203e0e89d2",
   "metadata": {},
   "source": [
    "# Evaluate GitHub Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16321896-dd05-48cf-995f-10b1a422a10f",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85944a5f-510a-4d95-8c14-4dc84d686b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_json_from_folder(folder_path):\n",
    "  \"\"\"\n",
    "  Loads all JSON files from a specified folder.\n",
    "\n",
    "  Args:\n",
    "    folder_path: The path to the folder containing the JSON files.\n",
    "\n",
    "  Returns:\n",
    "    A list containing all JSON objects from the files.\n",
    "  \"\"\"\n",
    "\n",
    "  data_packages = []\n",
    "  for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "      filepath = os.path.join(folder_path, filename)\n",
    "      try:\n",
    "        with open(filepath, 'r') as f:\n",
    "          data = json.load(f)\n",
    "          data_packages.append(data)\n",
    "      except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON in file {filename}: {e}\")\n",
    "          \n",
    "  return data_packages\n",
    "\n",
    "def load_json_from_file(json_file):\n",
    "    try:\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON in file {json_file}: {e}\")  # Corrected line\n",
    "        return None\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f71657c6-51e3-49d0-a246-9a2f7c5ac493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def validate_code(code_str):\n",
    "  \"\"\"\n",
    "  Validates Python code and returns error information if any.\n",
    "\n",
    "  Args:\n",
    "    code_str: The Python code as a string.\n",
    "\n",
    "  Returns:\n",
    "    None if the code is valid, otherwise a string describing the syntax error.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    ast.parse(code_str)\n",
    "    return None  # No error\n",
    "  except SyntaxError as e:\n",
    "    return str(e)  # Return the error message as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cff8a2ad-8a2e-4148-b42b-00fd2f8b9ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_key_in_json(json_obj, key_to_replace, new_value):\n",
    "  \"\"\"\n",
    "  Creates a new JSON object with a specific key replaced.\n",
    "\n",
    "  Args:\n",
    "    json_obj: The original JSON object.\n",
    "    key_to_replace: The key to be replaced.\n",
    "    new_value: The new value for the key.\n",
    "\n",
    "  Returns:\n",
    "    A new JSON object with the key replaced.\n",
    "  \"\"\"\n",
    "\n",
    "  new_json_obj = json.loads(json.dumps(json_obj))  # Create a deep copy\n",
    "  new_json_obj[key_to_replace] = new_value\n",
    "  return new_json_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f81b545-a086-4d14-9e7b-e98f1552fc3b",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e4d5c9-d2c5-4159-9845-93b683faeee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_python_dataset = \"../github-python-test\"\n",
    "\n",
    "# The original paper use the 3 4 as hold-out test set\n",
    "test_dataset = [];\n",
    "test_dataset.append(load_json_from_file(os.path.join(github_python_dataset, 'model-fixer.pred.evaluated.3.json')))\n",
    "test_dataset.append(load_json_from_file(os.path.join(github_python_dataset, 'model-fixer.pred.evaluated.4.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60761007-dc6f-486e-8f38-f6683c88463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 15055\n",
      "First code:\n",
      " def test_pp_no_constraint ( self ) :\n",
      "    filenames = [ tests . get_data_path ( ( \"str\" , \"str\" , \"str\" ) ) ]\n",
      "    pp_constraints = pp . _convert_constraints ( None )\n",
      "    pp_loader = iris . fileformats . rules . Loader ( pp . load , { } ,\n",
      "        convert , pp . _load_rules )\n",
      "    cubes = list ( load_cubes ( filenames , None , pp_loader , pp_constraints )\n",
      "    self . assertEqual ( len ( cubes ) , 152 )\n",
      "\n",
      "Error (if any): '(' was never closed (<unknown>, line 6)\n"
     ]
    }
   ],
   "source": [
    "total_samples = len(test_dataset[0]) + len(test_dataset[1])\n",
    "first_code = test_dataset[0][0]['src']['string_format']\n",
    "\n",
    "print(f\"Total number of samples: {total_samples}\")\n",
    "print(f\"First code:\\n {first_code}\")\n",
    "print(f\"Error (if any): {validate_code(first_code)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3706aab-3fd9-4c5b-832d-2e5b5bff6987",
   "metadata": {},
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "131e7764-fac2-4f45-a06b-17bc11b43be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8bffb0f-d0e4-4962-9b11-81f2d440527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set HF token as env variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a749d0b2-f689-4ad2-9cd3-5df08c198152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare token\n",
    "torch.cuda.empty_cache()\n",
    "hf_token = os.environ.get('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "568fa547-9692-4f03-a956-6787684c04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare instruction\n",
    "python_syntax_fixer_instruction = \"You are an expert Python code fixer. \\\n",
    "             You will receive input in the following format: \\n\\n \\\n",
    "             [Fix] | <error code>\\n \\\n",
    "             <python code snippet>\\n\\n \\\n",
    "             Your task is to ONLY provide the corrected Python code with NO explanations or additional text. \\n \\\n",
    "             Do not include the original error code in your response and do not format the code. \\\n",
    "             Treat the code snippet as regular text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6adc21a0-78b1-494c-b108-0af37cb0d9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c272429f4bbe43fcbae9dae98660775f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the model and instruction\n",
    "instruct_model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    token=hf_token,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d58c2-d3a6-465c-b6cc-40ee4b75362a",
   "metadata": {},
   "source": [
    "## Process fixing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6aedcc74-821c-4b64-bf09-5c02dc62d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_code(code_snippet):\n",
    "    code_error = validate_code(code_snippet)\n",
    "    messages = [\n",
    "        { \"role\": \"system\", \"content\": python_syntax_fixer_instruction }\n",
    "    ]\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"[Fix] | {code_error}\\n{code_snippet}\"})\n",
    "    \n",
    "    outputs = pipe(messages, max_new_tokens=512)\n",
    "    \n",
    "    return outputs[0][\"generated_text\"][-1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f249adb-e32e-466c-8d1f-4511e65b17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def perform_fixing_code(dataset):\n",
    "    results = []\n",
    "    for item in tqdm(dataset, desc=\"Fixing code\"):\n",
    "        code_snippet = item['src']['string_format']\n",
    "        \n",
    "        fixing_attempts = []\n",
    "        for _ in range(10):  # Fix 10 times\n",
    "            fixed_code = fix_code(code_snippet)\n",
    "            remain_error = validate_code(fixed_code)\n",
    "            fixing_attempts.append({\n",
    "                \"string_format\": fixed_code,\n",
    "                \"err_obj\": 0 if remain_error is None \\\n",
    "                            else { \"msg\": \"unbalanced (){}[]\", \"msg_detailed\": remain_error }\n",
    "            })\n",
    "\n",
    "        results.append(replace_key_in_json(item, \"pred\", fixing_attempts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f95bd-abbb-48cf-a152-1fd85d838ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dba988a77f49d1adb21e8b35a82d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fixing code:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "json_fixed_data = perform_fixing_code(test_dataset[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c96701c7-3977-412e-b1da-8cd3255d550d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f882f-e85d-4b19-894a-9b2231908c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # Write the results to a JSON file\n",
    "    with open(output_filename, \"w\") as outfile:\n",
    "        json.dump(results, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "979fac3e-225e-4aff-ba94-3f74143f8aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def test_pp_no_constraint ( self ) :\\n    filenames = [ tests . get_data_path ( ( \"str\" , \"str\" , \"str\" ) ) ]\\n    pp_constraints = pp . _convert_constraints ( None )\\n    pp_loader = iris . fileformats . rules . Loader ( pp . load , { } ,\\n        convert , pp . _load_rules )\\n    cubes = list ( load_cubes ( filenames , None , pp_loader , pp_constraints )\\n    self . assertEqual ( len ( cubes ) , 152 )\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b5b1883-c959-453c-a95f-b59423045cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6398b71b-be79-4ab4-8a69-e6959973a22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'def test_pp_no_constraint ( self ) :\\n    filenames = [ tests. get_data_path ( (\"str\", \"str\", \"str\") ) ]\\n    pp_constraints = pp._convert_constraints(None)\\n    pp_loader = iris.fileformats.rules.Loader(pp.load, {}, convert, pp._load_rules)\\n    cubes = list(load_cubes(filenames, None, pp_loader, pp_constraints))\\n    self.assertEqual(len(cubes), 152)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_code = fix_code(first_code)\n",
    "fixed_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb88badd-7a91-48d1-8f5d-455696b2b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_code(fixed_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e603a373-a5cb-4707-b737-0ea8cc6b0108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein distance: 53\n"
     ]
    }
   ],
   "source": [
    "distance = Levenshtein.distance(first_code, fixed_code)\n",
    "print(f\"Levenshtein distance: {distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab7b95-369e-4e92-89c5-565b9173d4f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e41cb4-95a3-4804-b0cd-b5f12a5ed56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cbf41-48f0-43f2-b573-ba4ff6fbe963",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a Python syntax error correction expert. You will receive code snippets with syntax errors, prefixed with [Fix]. Each input will have two parts separated by a vertical bar (|). You will only fix the provided code, without any additional explanation.\"},\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=128,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e39ccc-b21c-4226-ad33-59486c58504a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6defeb76a36f460b91cb495f58722cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'def greet(name):\\n  print(\"Hello, \" + name)'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "error_code = \"SyntaxError: invalid syntax\"\n",
    "code_snippet = \"\"\"\n",
    "def greet(name):\n",
    "  print(\"Hello, \" + name \n",
    "\n",
    "greet(\"Alice\")\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    { \n",
    "        \"role\": \"system\", \n",
    "        \"content\": \\\n",
    "            \"You are an expert Python code fixer. \\\n",
    "             You will receive input in the following format: \\n\\n \\\n",
    "             [Fix] | <error code>\\n \\\n",
    "             <python code snippet>\\n\\n \\\n",
    "             Your task is to ONLY provide the corrected Python code with NO explanations or additional text. \\n \\\n",
    "             Do not include the original error code in your response and do not format the code. \\\n",
    "             Treat the code snippet as regular text.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": f\"\"\"\n",
    "[Fix] | {error_code}\n",
    "{code_snippet}\n",
    "\"\"\"})\n",
    "\n",
    "outputs = pipe(messages, max_new_tokens=256)\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e59877aa-a023-439f-9b54-22c1d0ba5137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def greet(name):\\n  print(\"Hello, \" + name)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_code = outputs[0][\"generated_text\"][-1]['content']\n",
    "fixed_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed0263b8-c4df-48d5-820f-c1740a9e1133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'(' was never closed (<unknown>, line 3)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_code(code_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e3e0e23-20e7-4b6a-8dca-2cddca62e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_code(fixed_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e09ea6-79ce-472e-899f-c716c030db50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
