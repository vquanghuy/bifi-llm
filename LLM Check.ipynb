{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc5440b-b087-4c53-9f0f-e6e1802a7b26",
   "metadata": {},
   "source": [
    "# System Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd7f24-805e-475d-a83c-2c7b578e5000",
   "metadata": {},
   "source": [
    "- Python 3.10\n",
    "- PyTorch 2.5.0\n",
    "- Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d09578-3c1f-4b83-9439-1cc5ab162720",
   "metadata": {},
   "source": [
    "## Additional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e8267e-4aff-4667-b9f6-9246865a4667",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1ae8ec-7782-4afb-9857-333bf7572eab",
   "metadata": {},
   "source": [
    "Hugging Face Transformers at https://huggingface.co/docs/transformers/installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efec68e5-1083-4e25-9aa4-cf4acfd547a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flax\n",
      "  Downloading flax-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jax>=0.4.27 (from flax)\n",
      "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting msgpack (from flax)\n",
      "  Downloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting optax (from flax)\n",
      "  Downloading optax-0.2.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting orbax-checkpoint (from flax)\n",
      "  Downloading orbax_checkpoint-0.7.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorstore (from flax)\n",
      "  Downloading tensorstore-0.1.66-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting rich>=11.1 (from flax)\n",
      "  Downloading rich-13.9.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /opt/conda/lib/python3.11/site-packages (from flax) (4.11.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /opt/conda/lib/python3.11/site-packages (from flax) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from flax) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.4.27->flax)\n",
      "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
      "Collecting ml-dtypes>=0.2.0 (from jax>=0.4.27->flax)\n",
      "  Downloading ml_dtypes-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting opt-einsum (from jax>=0.4.27->flax)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting scipy>=1.10 (from jax>=0.4.27->flax)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown-it-py>=2.2.0 (from rich>=11.1->flax)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1->flax) (2.15.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Collecting absl-py>=0.7.1 (from optax->flax)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting chex>=0.1.86 (from optax->flax)\n",
      "  Downloading chex-0.1.87-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting etils[epy] (from optax->flax)\n",
      "  Downloading etils-1.10.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: nest_asyncio in /opt/conda/lib/python3.11/site-packages (from orbax-checkpoint->flax) (1.6.0)\n",
      "Collecting protobuf (from orbax-checkpoint->flax)\n",
      "  Downloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting humanize (from orbax-checkpoint->flax)\n",
      "  Downloading humanize-4.11.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Collecting toolz>=0.9.0 (from chex>=0.1.86->optax->flax)\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1->flax)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting importlib_resources (from etils[epath,epy]->orbax-checkpoint->flax)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting zipp (from etils[epath,epy]->orbax-checkpoint->flax)\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading flax-0.10.0-py3-none-any.whl (420 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m420.2/420.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.9/330.9 kB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading huggingface_hub-0.26.0-py3-none-any.whl (447 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jax-0.4.34-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m150.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.8/792.8 kB\u001b[0m \u001b[31m122.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.2-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m183.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m403.7/403.7 kB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading optax-0.2.3-py3-none-any.whl (289 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orbax_checkpoint-0.7.0-py3-none-any.whl (279 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.7/279.7 kB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorstore-0.1.66-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chex-0.1.87-py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/99.4 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl (86.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.1/86.1 MB\u001b[0m \u001b[31m153.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m256.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m201.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading humanize-4.11.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.1/128.1 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.28.2-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading etils-1.10.0-py3-none-any.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.9/164.9 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: zipp, toolz, scipy, safetensors, regex, protobuf, opt-einsum, msgpack, ml-dtypes, mdurl, importlib_resources, humanize, etils, absl-py, tensorstore, markdown-it-py, jaxlib, huggingface-hub, tokenizers, rich, jax, gdown, accelerate, transformers, orbax-checkpoint, chex, optax, flax\n",
      "Successfully installed absl-py-2.1.0 accelerate-1.0.1 chex-0.1.87 etils-1.10.0 flax-0.10.0 gdown-5.2.0 huggingface-hub-0.26.0 humanize-4.11.0 importlib_resources-6.4.5 jax-0.4.34 jaxlib-0.4.34 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.0 msgpack-1.1.0 opt-einsum-3.4.0 optax-0.2.3 orbax-checkpoint-0.7.0 protobuf-5.28.2 regex-2024.9.11 rich-13.9.2 safetensors-0.4.5 scipy-1.14.1 tensorstore-0.1.66 tokenizers-0.20.1 toolz-1.0.0 transformers-4.45.2 zipp-3.20.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install flax transformers accelerate gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6feffa-e141-4a94-9f24-8d06eb5d1271",
   "metadata": {},
   "source": [
    "# Load and check LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a84ad655-40cf-4c48-b830-05e847d16372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "hf_token = os.environ.get('HF_TOKEN')\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a code error generator. You will be provided with a number as input. Generate that many unique JavaScript code snippets, each containing at least one syntax error.  Output only the code snippets.\"},\n",
    "    {\"role\": \"user\", \"content\": \"5\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185461fc-943f-42d8-8637-8e5100407f6a",
   "metadata": {},
   "source": [
    "## Llama 3.1 8B Instruct\n",
    "\n",
    "Details: https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aeedf03b-3048-4d71-a132-6d59139a009c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cccd21cebaa4d568f6580126d3d5fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "pipe = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a765d653-eb5f-45fe-90a2-482edc31f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    "    pad_token_id=50256\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b87f20-d3db-404a-801d-f01ff002cce9",
   "metadata": {},
   "source": [
    "## Llama 3.2 3B Instruct\n",
    "\n",
    "Details: https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb8526-46fe-40cf-9d74-24b6c4fb6ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea9bd6-fa0f-42fd-992a-ce798fdf5b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    "    pad_token_id=50256\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1cc14-d318-40f5-b352-320a2dc5b9d5",
   "metadata": {},
   "source": [
    "## CodeLlama 7b Instruct\n",
    "\n",
    "Details https://huggingface.co/meta-llama/CodeLlama-7b-Instruct-hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b454cd-9f90-470a-9bcd-c5616a225f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/CodeLlama-7b-Instruct-hf\"\n",
    "\n",
    "pipe = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f618479b-de07-443f-b58a-f76e713a66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    "    pad_token_id=50256\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181a8a40-b782-4230-9cd0-2271276477f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76884859-7b3d-4cac-9bb8-0432573ca212",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### TFix dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c02265-6560-4d86-9114-2219bbd208b8",
   "metadata": {},
   "source": [
    "https://drive.google.com/file/d/1CtfnYaVf-q6FZP5CUM4Wh7ofpp8b9ajW/view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91802d0-18b1-458b-bf9e-a503e65672c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b5448-213a-4eb9-92d9-e0a94532e7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4773e5-d9f8-4cce-b7fe-fbc93c2181af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:  25%|█████████████████████████▊                                                                             | 1/4 [07:46<23:20, 466.84s/it]"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "hf_token = \"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\"\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.1-8B\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a46504df-ee6c-4c88-81b5-f0bd55796e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[cli] in /opt/conda/lib/python3.11/site-packages (0.26.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[cli]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[cli]) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[cli]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[cli]) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[cli]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[cli]) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[cli]) (4.11.0)\n",
      "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli])\n",
      "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli])\n",
      "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.43)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub[cli]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub[cli]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub[cli]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub[cli]) (2024.7.4)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.5)\n",
      "Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device: '/tmp/tmp11krsk0q'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub[\"cli\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c2af4db-b3d1-4b18-b3cd-14f19b84bd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/.cache/huggingface/hub\n"
     ]
    }
   ],
   "source": [
    "from transformers import file_utils\n",
    "print(file_utils.default_cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335690b-b5a5-4600-bb34-c2038a7aabdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
